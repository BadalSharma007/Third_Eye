{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Say 'start' to activate Bot Voice Assistant...\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "✅ Voice Assistant Activated.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "👤 You: direction\n",
      " I'm sorry, but I cannot give a direct answer without more context or information. Can you please provide more details or clarify your question? \n",
      "🤖 Bot:  I'm sorry, but I cannot give a direct answer without more context or information. Can you please provide more details or clarify your question? \n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "👤 You: direction mod\n",
      " Direction modulation is a method of modulating the carrier wave to transmit information. It allows the receiver to determine the direction from which the signal is coming. \n",
      "🤖 Bot:  Direction modulation is a method of modulating the carrier wave to transmit information. It allows the receiver to determine the direction from which the signal is coming. \n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "👤 You: ho sakta hai\n",
      " He does not know. \n",
      "🤖 Bot:  He does not know. \n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "❌ Speech not understood.\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "👤 You: Koi look wala\n",
      " Koi look beautiful, yes? \n",
      "🤖 Bot:  Koi look beautiful, yes? \n",
      "❌ TTS error\n",
      "🎤 Listening...\n",
      "🔎 Recognizing speech...\n",
      "👤 You: chutkule\n"
     ]
    }
   ],
   "source": [
    "# ✅ All final updates: start prompt, image+prompt input, short response control, direction mode, and strict model-only output\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import playsound\n",
    "import base64\n",
    "\n",
    "CHAT_HISTORY_FILE = \"chat_history.json\"\n",
    "AUDIO_FILE = \"bot_output.mp3\"\n",
    "BOT_URL = \"http://localhost:11434/api/generate\"\n",
    "ESP32_CAM_URL = \"http://192.168.217.184/camera\"\n",
    "IMAGE_FILE = \"latest.jpg\"\n",
    "\n",
    "start_prompts = [\"start\", \"let's start\", \"lets start\", \"suru karo\", \"started\"]\n",
    "exit_prompts = [\n",
    "    \"bye\", \"exit\", \"quit\", \"shutdown\", \"stop\", \"close\", \"turn off\",\n",
    "    \"band karo\", \"band kar do\", \"niklo\", \"khatam\", \"goodbye\", \"disconnect\", \"off\", \"okay bye\", \"ok bye\"\n",
    "]\n",
    "image_prompts = [\n",
    "    \"what is in front of me\", \"take a photo\", \"capture photo\",\n",
    "    \"show me what's ahead\", \"read it\", \"explain the surrounding\", \"read the book\",\n",
    "    \"which currency\", \"read currency\", \"mujhe kya dikh raha hai\", \"photo le lo\",\n",
    "    \"mere saamne kya hai\", \"kitni currency hai\", \"currency padho\", \"kya likha hai\"\n",
    "]\n",
    "direction_mode_trigger = [\"direction mode\"]\n",
    "stop_direction_trigger = [\"stop direction mode\"]\n",
    "\n",
    "def load_chat_history():\n",
    "    if os.path.isfile(CHAT_HISTORY_FILE):\n",
    "        try:\n",
    "            with open(CHAT_HISTORY_FILE, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def save_chat_history(history):\n",
    "    try:\n",
    "        with open(CHAT_HISTORY_FILE, 'w', encoding='utf-8') as file:\n",
    "            json.dump(history, file, indent=4)\n",
    "    except:\n",
    "        print(\"Error saving chat history\")\n",
    "\n",
    "def speech_to_text(prompt_msg=\"🎤 Listening...\"):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(prompt_msg)\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=3, phrase_time_limit=5)\n",
    "            print(\"🔎 Recognizing speech...\")\n",
    "            return recognizer.recognize_google(audio)\n",
    "        except:\n",
    "            print(\"❌ Speech not understood.\")\n",
    "            return None\n",
    "\n",
    "def text_to_speech(text):\n",
    "    try:\n",
    "        tts = gTTS(text, lang='en')\n",
    "        tts.save(AUDIO_FILE)\n",
    "        playsound.playsound(AUDIO_FILE)\n",
    "    except:\n",
    "        print(\"❌ TTS error\")\n",
    "\n",
    "def fetch_image():\n",
    "    try:\n",
    "        print(\"📸 Fetching image from ESP32-CAM...\")\n",
    "        response = requests.get(ESP32_CAM_URL, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            with open(IMAGE_FILE, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(\"✅ Image saved as latest.jpg\")\n",
    "            return IMAGE_FILE\n",
    "        else:\n",
    "            print(f\"❌ Failed to get image: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error fetching image: {e}\")\n",
    "    return None\n",
    "\n",
    "def send_image_and_prompt_to_bot(image_path, prompt_text):\n",
    "    print(\"📡 Sending image + prompt to Bot...\")\n",
    "    with open(image_path, \"rb\") as img:\n",
    "        image_data = img.read()\n",
    "        b64_image = base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "    if \"explain\" in prompt_text.lower():\n",
    "        prompt_to_send = f\"{prompt_text}. Respond in English only.\"\n",
    "    else:\n",
    "        prompt_to_send = f\"{prompt_text}. Respond in English only. Keep the answer within 13 words.\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llava\",\n",
    "        \"prompt\": prompt_to_send,\n",
    "        \"images\": [b64_image]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(BOT_URL, headers={\"Content-Type\": \"application/json\"}, json=data, stream=True) as response:\n",
    "            response.raise_for_status()\n",
    "            full_response = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    result = json.loads(line)\n",
    "                    text = result.get(\"response\", \"\")\n",
    "                    print(text, end='', flush=True)\n",
    "                    full_response += text\n",
    "            return full_response\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error talking to Bot: {e}\")\n",
    "        return \"I'm not sure what's in front of you.\"\n",
    "\n",
    "def send_text_prompt_to_bot(prompt_text):\n",
    "    if \"explain\" in prompt_text.lower():\n",
    "        prompt_to_send = f\"{prompt_text}. Respond in English only.\"\n",
    "    else:\n",
    "        prompt_to_send = f\"{prompt_text}. Respond in English only. Keep the answer within 13 words.\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llava\",\n",
    "        \"prompt\": prompt_to_send,\n",
    "        \"images\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(BOT_URL, headers={\"Content-Type\": \"application/json\"}, json=data, stream=True) as response:\n",
    "            response.raise_for_status()\n",
    "            full_response = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    result = json.loads(line)\n",
    "                    text = result.get(\"response\", \"\")\n",
    "                    print(text, end='', flush=True)\n",
    "                    full_response += text\n",
    "            return full_response\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error querying Bot: {e}\")\n",
    "        return \"Something went wrong.\"\n",
    "\n",
    "def handle_prompt(prompt):\n",
    "    clear_triggers = [\n",
    "        \"clear history\", \"delete chat\", \"reset conversation\", \"delete history\",\n",
    "        \"clear chat\", \"chat clear kar do\", \"history hata do\", \"clear karo\"\n",
    "    ]\n",
    "\n",
    "    if any(phrase in prompt.lower() for phrase in clear_triggers):\n",
    "        if os.path.exists(CHAT_HISTORY_FILE):\n",
    "            os.remove(CHAT_HISTORY_FILE)\n",
    "            print(\"🗑️ Chat history deleted.\")\n",
    "            text_to_speech(\"Chat history cleared.\")\n",
    "        else:\n",
    "            print(\"⚠️ No chat history found.\")\n",
    "            text_to_speech(\"There was no history to delete.\")\n",
    "        return\n",
    "\n",
    "    if any(phrase in prompt.lower() for phrase in direction_mode_trigger):\n",
    "        text_to_speech(\"Direction mode activated. Say 'stop direction mode' to exit.\")\n",
    "        while True:\n",
    "            image_path = fetch_image()\n",
    "            if not image_path:\n",
    "                text_to_speech(\"Could not capture image.\")\n",
    "                break\n",
    "            direction_response = send_image_and_prompt_to_bot(image_path, \"Give movement suggestion without saying to look\")\n",
    "            print(f\"\\n🤖 Bot: {direction_response}\")\n",
    "            text_to_speech(direction_response)\n",
    "            print(\"🎤 Say 'stop direction mode' to exit or wait for next direction...\")\n",
    "            try:\n",
    "                command = speech_to_text(\"🎧 Listening for stop command...\")\n",
    "                if command and any(phrase in command.lower() for phrase in stop_direction_trigger):\n",
    "                    text_to_speech(\"Exiting direction mode.\")\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        return\n",
    "\n",
    "    if any(img_trigger in prompt.lower() for img_trigger in image_prompts):\n",
    "        image_path = fetch_image()\n",
    "        if not image_path:\n",
    "            text_to_speech(\"Failed to capture image.\")\n",
    "            return\n",
    "        spoken_prompt = speech_to_text(\"🎧 What should I describe in this image?\")\n",
    "        if not spoken_prompt:\n",
    "            text_to_speech(\"I didn't catch that.\")\n",
    "            return\n",
    "        response = send_image_and_prompt_to_bot(image_path, spoken_prompt)\n",
    "        print(f\"\\n🤖 Bot: {response}\")\n",
    "        text_to_speech(response)\n",
    "        chat_history = load_chat_history()\n",
    "        chat_history.append({\"user\": spoken_prompt, \"llava\": response})\n",
    "        save_chat_history(chat_history)\n",
    "        return\n",
    "\n",
    "    response = send_text_prompt_to_bot(prompt)\n",
    "    print(f\"\\n🤖 Bot: {response}\")\n",
    "    text_to_speech(response)\n",
    "    chat_history = load_chat_history()\n",
    "    chat_history.append({\"user\": prompt, \"llava\": response})\n",
    "    save_chat_history(chat_history)\n",
    "\n",
    "def main():\n",
    "    print(\"🧠 Say 'start' to activate Bot Voice Assistant...\")\n",
    "    while True:\n",
    "        first_prompt = speech_to_text()\n",
    "        if first_prompt and first_prompt.strip().lower() in start_prompts:\n",
    "            print(\"✅ Voice Assistant Activated.\")\n",
    "            break\n",
    "\n",
    "    while True:\n",
    "        prompt = speech_to_text()\n",
    "        if prompt:\n",
    "            print(f\"👤 You: {prompt}\")\n",
    "            if prompt.strip().lower() in exit_prompts:\n",
    "                print(\"👋 Exiting.\")\n",
    "                break\n",
    "            handle_prompt(prompt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
